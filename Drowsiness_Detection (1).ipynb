{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5G6W6xtvhZnL"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QszUTA6uhkCW"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gONetr3hsBQ"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDh3HBjxh1rU"
      },
      "outputs": [],
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WmqFDmzh7qH"
      },
      "outputs": [],
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3nfwW60kkWr"
      },
      "outputs": [],
      "source": [
        "! kaggle datasets list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEAwUDc8lNAn"
      },
      "outputs": [],
      "source": [
        "! kaggle datasets download -d ismailnasri20/driver-drowsiness-dataset-ddd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McNYjYjgmBBU"
      },
      "outputs": [],
      "source": [
        "! unzip driver-drowsiness-dataset-ddd.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSjuOWUYljFI"
      },
      "source": [
        "# **TRANSFER LEARNING WITH MOBILENETV2**\n",
        "\n",
        "\n",
        "1.   Load a pretrained network instead of training our own from scratch\n",
        "2.   These models are usually trained on much larger datasets with many more classes\n",
        "\n",
        "1.   We use pretrained weights as a feature extractor and then apply our own classification later for our application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7wd2SD1lmNC"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "os.environ['CUDA_DEVICE_ORDER']=\"PCI_BUS_ID\"\n",
        "os.environ['CUDA_VISIBLE_DEVICES']=\"0\"\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator as data_augment\n",
        "from keras.models import Model,Sequential\n",
        "from keras.layers import Input,MaxPooling2D,Dropout,Flatten,Dense,GlobalAveragePooling2D,BatchNormalization\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from tensorflow.keras import layers as layers\n",
        "\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if len(device_name) > 0:\n",
        "    print(\"Found GPU at: {}\".format(device_name))\n",
        "else:\n",
        "    device_name = \"/device:CPU:0\"\n",
        "    print(\"No GPU, using {}.\".format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KO9_PntrnIQ0"
      },
      "source": [
        "# **DATA PREPROCESSING AND AUGMENTATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CC-Q3k7nVEg"
      },
      "outputs": [],
      "source": [
        "#data augmetation \n",
        "data_generate_training = data_augment (rescale=1./255, \n",
        "                              shear_range = 0.2,\n",
        "                              zoom_range = 0.2,\n",
        "                              fill_mode = \"nearest\",\n",
        "                              horizontal_flip = True,\n",
        "                              width_shift_range = 0.2,\n",
        "                              height_shift_range = 0.2,\n",
        "                              validation_split = 0.15)\n",
        "\n",
        "data_generate_test = data_augment(rescale = 1./255)\n",
        "\n",
        "#data preprocessing and augmentation\n",
        "traind = data_generate_training.flow_from_directory(\"/content/Driver Drowsiness Dataset (DDD)\",\n",
        "                                          target_size = (224, 224),\n",
        "                                          seed = 123,\n",
        "                                          batch_size = 32,\n",
        "                                          subset = \"training\")\n",
        "\n",
        "testd = data_generate_training.flow_from_directory(\"/content/Driver Drowsiness Dataset (DDD)\",\n",
        "                                          target_size = (224, 224),\n",
        "                                          seed = 123,\n",
        "                                          batch_size = 32,\n",
        "                                          subset = \"validation\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx-LqOr-jmKR"
      },
      "source": [
        "# **BUILD MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiUw4KwxjoSi"
      },
      "outputs": [],
      "source": [
        "base_model= MobileNetV2(weights='imagenet', include_top=False)\n",
        "\n",
        "x= base_model.output\n",
        "x= GlobalAveragePooling2D()(x)\n",
        "x= Dense(512, activation='relu')(x)\n",
        "x= Dense(256, activation='relu')(x)\n",
        "x= Dense(128, activation='relu')(x)\n",
        "preds= Dense(2, activation='softmax')(x)\n",
        "\n",
        "\n",
        "\n",
        "model= Model(inputs=base_model.input, outputs=preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHRx2GVdmTYQ"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8agM9CnEWVF"
      },
      "outputs": [],
      "source": [
        "print(traind.image_shape)\n",
        "print(testd.image_shape)\n",
        "print(model.output_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_xQOOp4nBi8"
      },
      "source": [
        "# **COMPILING AND MODELLING DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYoP2PhwonGR"
      },
      "outputs": [],
      "source": [
        "epochs= 15\n",
        "optmizer= Adam(learning_rate=.0001)\n",
        "model.compile(loss='categorical_crossentropy',optimizer=optmizer, metrics=['accuracy'])\n",
        "! pip install -q pyyaml h5py  # Required to save models in HDF5 format\n",
        "\n",
        "filepath = '/content/drive/'\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath= filepath, \n",
        "                                                         save_weights_only=True, save_best_only=True)\n",
        "model.fit(traind, epochs=epochs, validation_data=testd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wluQfrSWB_0B"
      },
      "source": [
        "# **MODEL CONVERSION TO TENSORFLOW.JS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1Y2-I8lCFlM"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import model_from_json\n",
        "model_in_json= model.to_json()\n",
        "with open('/content/model.json', 'w') as json_file:\n",
        "  json_file.write(model_in_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuvYRQhRAOJ9"
      },
      "outputs": [],
      "source": [
        "#Loading model from JSON file\n",
        "model_file=open('model.json','r')\n",
        "json_model=model_file.read()\n",
        "model2= model_from_json(json_model,{\"tf\":tf})\n",
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjZk6LFo9Pgr"
      },
      "outputs": [],
      "source": [
        "#Saving models and weights in h5 format\n",
        "\n",
        "model.save('model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zBXRVop9l2X"
      },
      "outputs": [],
      "source": [
        "#Loading the h5 model\n",
        "from tensorflow.keras.models import load_model\n",
        "model4=load_model('model.h5')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
