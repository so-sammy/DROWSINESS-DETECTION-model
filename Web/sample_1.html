<html>

<head>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"> </script>

    <style>
        body {
            font-family: roboto;
            margin: 2em;
            color: #3d3d3d;
            --mdc-theme-primary: #007f8b;
            --mdc-theme-on-primary: #f1f3f4;
        }

        h1 {
            color: #007f8b;
        }

        h2 {
            clear: both;
        }

        em {
            font-weight: bold;
        }

        video {
            clear: both;
            display: block;
            transform: rotateY(180deg);
            -webkit-transform: rotateY(180deg);
            -moz-transform: rotateY(180deg);
        }

        section {
            opacity: 1;
            transition: opacity 500ms ease-in-out;
        }

        .mdc-button.mdc-button--raised.removed {
            display: none;
        }

        .invisible {
            opacity: 0.2;
        }

        .videoView,
        .detectOnClick {
            position: relative;
            float: left;
            width: 48%;
            margin: 2% 1%;
            cursor: pointer;
        }

        .detectOnClick p {
            position: absolute;
            padding: 5px;
            background-color: #007f8b;
            color: #fff;
            border: 1px dashed rgba(255, 255, 255, 0.7);
            z-index: 2;
            font-size: 12px;
            margin: 0;
        }

        .videoView p {
            position: absolute;
            padding-bottom: 5px;
            padding-top: 5px;
            background-color: #007f8b;
            color: #fff;
            border: 1px dashed rgba(255, 255, 255, 0.7);
            z-index: 2;
            font-size: 12px;
            margin: 0;
        }

        .highlighter {
            background: rgba(0, 255, 0, 0.25);
            border: 1px dashed #fff;
            z-index: 1;
            position: absolute;
        }

        .detectOnClick {
            z-index: 0;
        }

        .detectOnClick img {
            width: 100%;
        }

        .key-point {
            position: absolute;
            z-index: 1;
            width: 3px;
            height: 3px;
            background-color: #ff0000;
            /* border: 1px solid #ffffff; */
            border-radius: 50%;
            display: block;
        }
    </style>
</head>

<body>
    <link href="https://unpkg.com/material-components-web@latest/dist/material-components-web.min.css" rel="stylesheet">
    <script src="https://unpkg.com/material-components-web@latest/dist/material-components-web.min.js"></script>


    <section id="demos" class="invisible" style="text-align:center">
        <h1>Face detection using the MediaPipe Face Detector task</h1>
        <h2>Demo: Detecting Faces</h2>
        <p><b>Click on an image below</b> to detect faces in the image.</p>

        <div class="detectOnClick">
            <img src="https://assets.codepen.io/9177687/female-4572747_640.jpg" width="100%" crossorigin="anonymous"
                title="Click to get classification!" />
        </div>
        <div class="detectOnClick">
            <img src="https://assets.codepen.io/9177687/idea-gcbe74dc69_1920.jpg" width="100%" crossorigin="anonymous"
                title="Click to get classification!" />
        </div>
    </section>

    <script type="module">
        import {
            FilesetResolver,
            FaceDetector
        } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.1.0-alpha-16";

        //FACE DETECTION
        const demosSection = document.getElementById("demos");

        let faceDetector;
        let runningMode = "IMAGE";

        // Initialize the object detector
        const initializefaceDetector = async () => {
            const vision = await FilesetResolver.forVisionTasks(
                "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
            );
            faceDetector = await FaceDetector.createFromOptions(vision, {
                baseOptions: {
                    modelAssetPath: "https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite",
                    delegate: "GPU"
                },
                runningMode: runningMode
            });
            demosSection.classList.remove("invisible");
        };
        initializefaceDetector();
        /********************************************************************
         // Demo 1: Grab a bunch of images from the page and detection them
         // upon click.
         ********************************************************************/

        const imageContainers = document.getElementsByClassName("detectOnClick");

        for (let imageContainer of imageContainers) {
            imageContainer.children[0].addEventListener("click", handleClick);
        }

        /**
         * Detect faces in still images on click
         */
        async function handleClick(event) {
            const highlighters = event.target.parentNode.getElementsByClassName(
                "highlighter"
            );
            while (highlighters[0]) {
                highlighters[0].parentNode.removeChild(highlighters[0]);
            }

            const infos = event.target.parentNode.getElementsByClassName("info");
            while (infos[0]) {
                infos[0].parentNode.removeChild(infos[0]);
            }
            const keyPoints = event.target.parentNode.getElementsByClassName("key-point");
            while (keyPoints[0]) {
                keyPoints[0].parentNode.removeChild(keyPoints[0]);
            }

            if (!faceDetector) {
                console.log("Wait for objectDetector to load before clicking");
                return;
            }

            // if video mode is initialized, set runningMode to image
            if (runningMode === "VIDEO") {
                runningMode = "IMAGE";
                await faceDetector.setOptions({ runningMode: "IMAGE" });
            }

            const ratio = event.target.height / event.target.naturalHeight;

            // faceDetector.detect returns a promise which, when resolved, is an array of Detection faces
            const detections = await faceDetector.detect(event.target).detections;
            console.log(detections);

            displayImageDetections(detections, event.target);
        }
        function displayImageDetections(detections, resultElement) {
            const ratio = resultElement.height / resultElement.naturalHeight;

            for (let detection of detections) {
                console.log("Face bounding box:", detection.boundingBox);
                // Description text
                const p = document.createElement("p");
                p.setAttribute("class", "info");
                p.innerText =
                    "Confidence: " +
                    Math.round(parseFloat(detection.categories[0].score) * 100) +
                    "% .";
                // Positioned at the top left of the bounding box.
                // Height is whatever the text takes up.
                // Width subtracts text padding in CSS so fits perfectly.
                p.style =
                    "left: " +
                    detection.boundingBox.originX * ratio +
                    "px;" +
                    "top: " +
                    (detection.boundingBox.originY * ratio - 30) +
                    "px; " +
                    "width: " +
                    (detection.boundingBox.width * ratio - 10) +
                    "px;" +
                    "height: " +
                    20 +
                    "px;";
                const highlighter = document.createElement("div");
                highlighter.setAttribute("class", "highlighter");
                highlighter.style =
                    "left: " +
                    detection.boundingBox.originX * ratio +
                    "px;" +
                    "top: " +
                    detection.boundingBox.originY * ratio +
                    "px;" +
                    "width: " +
                    detection.boundingBox.width * ratio +
                    "px;" +
                    "height: " +
                    detection.boundingBox.height * ratio +
                    "px;";

                resultElement.parentNode.appendChild(highlighter);
                resultElement.parentNode.appendChild(p);
                for (let keypoint of detection.keypoints) {
                    const keypointEl = document.createElement("span");
                    keypointEl.className = "key-point";
                    keypointEl.style.top = keypoint.y * resultElement.height - 3 + "px";
                    keypointEl.style.left = keypoint.x * resultElement.width - 3 + "px";
                    resultElement.parentNode.appendChild(keypointEl);
                }
            }
        }
    </script>
</body>

</html>